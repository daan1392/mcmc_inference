%% 
%% Copyright 2007-2025 Elsevier Ltd
%% 
%% This file is part of the 'Elsarticle Bundle'.
%% ---------------------------------------------
%% 
%% It may be distributed under the conditions of the LaTeX Project Public
%% License, either version 1.3 of this license or (at your option) any
%% later version.  The latest version of this license is in
%%    http://www.latex-project.org/lppl.txt
%% and version 1.3 or later is part of all distributions of LaTeX
%% version 1999/12/01 or later.
%% 
%% The list of all files belonging to the 'Elsarticle Bundle' is
%% given in the file `manifest.txt'.
%% 
%% Template article for Elsevier's document class `elsarticle'
%% with harvard style bibliographic references

% \documentclass[preprint,12pt]{elsarticle}

%% Use the option review to obtain double line spacing
% \documentclass[preprint,review,12pt]{elsarticle}

%% Use the options 1p,twocolumn; 3p; 3p,twocolumn; 5p; or 5p,twocolumn
%% for a journal layout:
%% \documentclass[final,1p,times]{elsarticle}
%% \documentclass[final,1p,times,twocolumn]{elsarticle}
\documentclass[final,3p,times]{elsarticle}

\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{subcaption}
\usepackage{graphicx}
\usepackage{hyperref}


%% The lineno packages adds line numbers. Start line numbering with
%% \begin{linenumbers}, end it with \end{linenumbers}. Or switch it on
%% for the whole article with \linenumbers.
\usepackage{lineno}

\journal{Nuclear Physics B}
\newcommand{\keff}{$k_\text{eff}$}
\newcommand{\nuclide}[2]{$^{#1}$#2}

\begin{document}

\begin{frontmatter}

%% Title, authors and addresses

%% use the tnoteref command within \title for footnotes;
%% use the tnotetext command for theassociated footnote;
%% use the fnref command within \author or \affiliation for footnotes;
%% use the fntext command for theassociated footnote;
%% use the corref command within \author for corresponding author footnotes;
%% use the cortext command for theassociated footnote;
%% use the ead command for the email address,
%% and the form \ead[url] for the home page:
% \title{Title\tnoteref{label1}}
% \tnotetext[label1]{}
\author[sckcen,ulb,epfl]{Daan Houben}
\ead{daan.houben@sckcen.be}
% \ead[url]{home page}
% \fntext[label2]{}
% \cortext[cor1]{}
% \affiliation{organization={},
%             addressline={},
%             city={},
%             postcode={},
%             state={},
%             country={}}
% \fntext[label3]{}

\title{Bayesian Optimisation using microscopic and integral measurements to infer nuclear data parameters} %% Article title

%% use optional labels to link authors explicitly to addresses:
% \author[sckcen,ulb]{Daan Houben}
\author[epfl]{Mathieu Hursin}
\author[sckcen]{Luca Fiorito}
\author[ulb]{Pierre-Etienne Labeau}
\author[sckcen]{Gert Van den Eynde}
\affiliation[sckcen]{organization={The Belgian Nuclear Research Center (SCK CEN)},
            addressline={Boeretang 190},
            city={Mol},
            postcode={2400},
            state={Antwerp},
            country={Belgium}}.
\affiliation[ulb]{organization={Université Libre de Bruxelles (ULB)},
            addressline={Av. Franklin Roosevelt 50},
            city={Bruxelles},
            postcode={1050},
            state={Bruxelles},
            country={Belgium}}
\affiliation[epfl]{organization={École Polytechnique Fédérale de Lausanne (EFPL)},
            addressline={Rte Cantonale},
            city={Lausanne},
            postcode={1015},
            state={Vaud},
            country={Switzerland}}

%% Abstract
\begin{abstract}
%% Text of abstract
Abstract text.
\end{abstract}

%%Graphical abstract
\begin{graphicalabstract}
%\includegraphics{grabs}
\end{graphicalabstract}

%%Research highlights
\begin{highlights}
\item Research highlight 1
\item Research highlight 2
\end{highlights}

%% Keywords
\begin{keyword}
%% keywords here, in the form: keyword \sep keyword
Nuclear data \sep MCMC \sep data assimilation \sep Chromium
%% PACS codes here, in the form: \PACS code \sep code

%% MSC codes here, in the form: \MSC code \sep code
%% or \MSC[2008] code \sep code (2000 is the default)

\end{keyword}

\end{frontmatter}

%% Add \usepackage{lineno} before \begin{document} and uncomment 
%% following line to enable line numbers
\linenumbers

%% main text
%%

%% Use \section commands to start a section
\section{Introduction}
Nuclear data is considered the major source of uncertainty in several reactor observables, most notably the effective multiplication factor (\keff{}). The nuclear data available in evaluated nuclear data libraries, such as cross sections, neutron multiplicities, angular distributions, and fission neutron energy spectra, are the result of a complex fitting procedure involving theoretical models, microscopic experiments, and expert judgment. Integral experiments are subsequently used to assess the performance of this nuclear data. In this work, a Bayesian Optimization (BO) framework is proposed to consolidate microscopic energy-dependent measurements with integral experiments for the estimation of nuclear data parameters.

The BO is performed using a Markov Chain Monte Carlo (MCMC) method, in which surrogates are employed to evaluate the likelihoods. For the microscopic energy-dependent measurements, the SAMMY v8.1.0 resonance fitting tool \cite{larsonUpdatedUsersGuide2008} is employed, while SERPENT v2.2.2 \cite{leppanenSerpentMonteCarlo2015}, a Monte Carlo neutron transport code, is used to quantify the integral response. Surrogates are trained by evaluating random samples drawn in the input space using these high-fidelity models. The methodology is tested on a case study involving \nuclide{53}{Cr}. Since microscopic experiments typically provide a dense set of data points while integral experiments provide a single values integrated over several nuclides/reactions/energies, special care is taken to analyze how different assumptions regarding the likelihood evaluation and data correlation affect the posterior distribution.

\section{Background and Mathematical Motivation}
\subsection{Bayesian Optimization Setup}
The main objective of this paper is to infer nuclear data parameter(s) from a combined set of microscopic energy-dependent and integral experiments. Microscopic energy-dependent measurements (hereafter referred to as microscopic measurements) quantify single-energy neutron properties. These often result from neutron Time-Of-Flight (nTOF) facilities, where the neutron energy is derived from the time of flight to a target. A characteristic of these measurements is the high density of data points obtained. In contrast, integral measurements, such as criticality experiments, provide a single value representative of a macroscopic group of nuclides, reactions, and energies.

According to Bayes' theorem, the posterior (updated) probability density function (PDF), $P(\theta|\text{data})$, is proportional to the likelihood of observing the parameter(s) $\theta$ given the data, multiplied by the prior belief regarding the parameter(s):
\begin{equation}
    P(\theta|\text{data}) \propto  P(\text{data}|\theta)\cdot P(\theta)
\end{equation}
For brevity, we refer to the likelihood as $\mathcal{L}(\theta)=P(\text{data}|\theta)$.

\subsection{Markov Chain Monte Carlo (MCMC)}
To calculate the posterior distribution, various techniques derived from Bayes' theorem can be employed, such as Generalized Linear Least Squares (GLLS) \cite{hoeferLimitationsGeneralizedLinear}, Bayesian Monte Carlo (BMC) \cite{rochmanMonteCarloNuclear2018a}, and MOCABA \cite{hoeferMOCABAGeneralMonte2015}. In this paper, we select an algorithm belonging to the family of Markov Chain Monte Carlo (MCMC) techniques. 

In most MCMC algorithms, the unnormalized posterior is evaluated for each sample as
\begin{equation}
    P^*(\theta | \text{data}) = \mathcal{L}(\theta) \cdot P(\theta),
\end{equation}
where $P^*(\theta | \text{data})$ represents the posterior up to a normalizing constant. The objective is to construct a Markov chain $\{\theta_0, \theta_1, \dots, \theta_N\}$ such that the stationary distribution of the chain converges to the posterior distribution $P(\theta|\text{data})$. Under the assumption of a Normally distributed prior ($\mathcal{N}(\mathbf{\theta_0}, \mathbf{\Sigma})$) and likelihood ($\mathcal{N} (\mathbf{y_\text{true}}, \mathbf{A})$), the unnormalized posterior probability evaluated at $\theta$ can be rewritten as
\begin{equation}
    \begin{split}
        P^*(\theta | \text{data}) = \frac{1}{\sqrt{(2\pi)^m\det\mathbf{A}}}\exp\left[-\frac{1}{2}(\mathbf{f(\theta)}-\mathbf{y_{\text{exp}}})^T\mathbf{A}^{-1}(\mathbf{f(\theta)}-\mathbf{y_{\text{exp}}})\right]& \times \\ \frac{1}{\sqrt{(2\pi)^n\det\mathbf{\Sigma}}}\exp\left[-\frac{1}{2}( \mathbf{\theta_{0}}-\mathbf{\theta})^T\mathbf{\Sigma}^{-1}(\mathbf{\theta_{0}}-\mathbf{\theta})\right]&
    \end{split}
\end{equation}
The first term represents the probability of observing $\mathbf{\theta}$ given the measurements, where $\mathbf{y_\text{exp}}$ is the vector describing the $m$ measurement points, $\mathbf{f(\theta)}$ is the vector containing the model responses for the vector $\mathbf{\theta}$, and $\mathbf{A}$ is the covariance matrix describing the measurement points of size $(m \times m)$. The prior probability is calculated using the prior belief of the $n$ parameters $\mathbf{\theta_0}$, with a covariance matrix $\mathbf{\Sigma}$ of size $(n\times n)$. 

Standard algorithms, such as Metropolis-Hastings, propose a new state $\theta'$ based on a proposal distribution $q(\theta'|\theta_t)$ and accept it with probability $\alpha$. However, as Metropolis-Hastings algorithms require tuning, we employ the Affine Invariant Ensemble Sampler (AIES), as implemented in the \textit{emcee} code \cite{emcee}. In this algorithm, an ensemble of $K$ "walkers" is propagated in parallel. The proposal step for a walker $\theta_k$ is based on the current position of a complementary walker $\theta_j$ from the ensemble:
\begin{equation}
    \theta_k' = \theta_j + Z (\theta_k - \theta_j)
\end{equation}
where $Z$ is a scaling variable drawn from a distribution $g(z) \propto 1/\sqrt{z}$ on the interval $[1/a, a]$. This "stretch move" allows the algorithm to efficiently sample distributions with strong correlations without requiring manual tuning of the proposal covariance matrix.

\subsection{Likelihood Formulation}
The formulation of the likelihood function $\mathcal{L}(\theta)$ is one of the challenges when combining integral and microscopic data. The quantity of data points differs by orders of magnitude, which may dilute the effect of the integral measurement. To better understand the extent to which microscopic measurements might dilute these integral measurements, we analyze different approaches to include the microscopic experiments.

Ideally, one would use the full experimental covariance matrix. However, calculating experimental correlations between distinct integral experiments, distinct microscopic, and between microscopic and integral experiments, is inherently difficult and time consuming. We therefore currently introduce the assumption that there are no correlations between microscopic and integral experiments, nor between integral or microscopic experiments from different facilities. This allows us to calculate the total likelihood $\mathcal{L}(\mathbf{\theta})$ for a set of microscopic experiments $J$ and integral experiments $I$:
\begin{equation}
    \begin{split}
        \mathcal{L} (\mathbf{\theta}) = \prod_{j\in J} \frac{1}{\sqrt{(2\pi)^{m_j}\det\mathbf{A_j}}}\exp\left[-\frac{1}{2}(\mathbf{f_j(\theta)}-\mathbf{y_{j}})^T\mathbf{A_j}^{-1}(\mathbf{f_j(\theta)}-\mathbf{y_{j}})\right] & \times \\
        \prod_{i\in I} \frac{1}{\sqrt{2\pi\sigma^2_i}}\exp\left[-\frac{(f_i(\mathbf{\theta})-y_{i})^2}{2\sigma_{i}^2}\right]
    \end{split}
\end{equation}
Using the log-likelihood $\ln\mathcal{L}(\theta)$ for numerical stability:
\begin{equation}\label{eq:loglikelihood}
    \begin{split}
        \ln\mathcal{L} (\mathbf{\theta}) = -\frac{1}{2} \sum_{j\in J} \ln\left[(2\pi)^{m_j}\det\mathbf{A_j}\right] - \frac{1}{2}\sum_{j\in J}\left[(\mathbf{f_j(\theta)}-\mathbf{y_{j}})^T\mathbf{A_j}^{-1}(\mathbf{f_j(\theta)}-\mathbf{y_{j}})\right] & + \\
        -\frac{1}{2}\sum_{i\in I} \ln \left[2\pi\sigma^2_i\right] - \frac{1}{2}\sum_{i\in I}\frac{(f_i(\mathbf{\theta})-y_{i})^2}{\sigma_{i}^2} 
    \end{split}
\end{equation}
We analyze two approximations regarding the microscopic data: (1) all microscopic measurement points behave fully independently, and (2) microscopic points within a single experiment are fully correlated (correlation coefficient of 1) while remaining independent of other experiments.

\subsubsection{Independent microscopic measurement points}
If all measurement points are independent, each microscopic point carries the same weight as an integral experiment. Consequently, the integral experiments are likely to be diluted and their influence on the posterior negligible. This makes the inference overconfident in the microscopic experiments. The log-likelihood from Eq. \ref{eq:loglikelihood} becomes:
\begin{equation}\label{eq:independent}
    \begin{split}
        \ln\mathcal{L}_J (\mathbf{\theta}) &= -\frac{1}{2} \sum_{j\in J}\sum_{e\in E_j} \ln\left[2\pi\sigma_{j,e}^2\right] - \frac{1}{2}\sum_{j\in J}\sum_{e\in E_j}\left[\frac{(f_{j,e}(\mathbf{\theta})-y_{j,e})^2}{\sigma_{j,e}^2}\right] \\
        &= C -\frac{1}{2}\sum_{j\in J}\chi^2_j
    \end{split}
\end{equation}
where $\chi^2$ is the standard goodness-of-fit. The logarithmic term is constant with respect to $\theta$ and is replaced by $C$.

\subsubsection{Fully correlated microscopic measurement points}
Conversely, if we assume microscopic points are fully correlated, we normalize by the degrees of freedom ($N$), which may be interpreted as taking the average. Eq. \ref{eq:loglikelihood} then becomes
\begin{equation}\label{eq:correlated}
    \begin{split}
        \ln\mathcal{L}_J (\mathbf{\theta}) &= -\frac{1}{2} \sum_{j\in J}\frac{1}{N}\sum_{e\in E_j} \ln\left[2\pi\sigma_{j,e}^2\right] - \frac{1}{2}\sum_{j\in J}\frac{1}{N}\sum_{e\in E_j}\left[\frac{(f_{j,e}(\mathbf{\theta})-y_{j,e})^2}{\sigma_{j,e}^2}\right] \\
        &= C -\frac{1}{2}\sum_{j\in J}\chi^2_{\text{N},j},
    \end{split}
\end{equation}
where $\chi_{N,j}^2$ is the chi-squared per degree of freedom for microscopic experiment $j$. In this approximation, we are too conservative and do not trust the microscopic experiment sufficiently. Eventually, including the full experimental covariance matrix will result in a likelihood which is inbetween the result obtained by Eqs. \ref{eq:independent} and \ref{eq:correlated}. 

\subsection{Surrogate Modelling}
The MCMC algorithm requires thousands of likelihood evaluations. Directly executing high-fidelity codes (SAMMY and SERPENT) at each step is computationally expensive. We therefore employ Gaussian Process (GP) regression as a surrogate model. A GP defines a probability distribution over all possible functions consistent with the observed data, providing both a predicted mean and an associated variance. This variance can then be included in the likelihood calculation and allows the MCMC sampler to avoid overconfidence in less explored regions of the input space. 

To train the surrogates, a dataset is generated by drawing uniform random samples across the input space. For microscopic experiments, SAMMY calculates the $\chi^2$ metric. For integral experiments, SERPENT calculates \keff{}. The dataset is split 80/20 for training and testing. We utilize a Radial Basis Function (RBF) kernel for the integral experiments (as \keff{} behaves smoothly) and a polynomial kernel of second degree for the microscopic $\chi^2$ response (as $\chi^2$  is inherently quadratic). A white noise kernel is added to account for Monte Carlo statistical uncertainty and to ensure positive definiteness.

\subsection{Including Uncertainties of Other Nuclides}
To limit the Bayesian Optimization from compensating for biases induced by other sources, next to the uncertainties introduced by material and geometry specifications, uncertainties from other nuclides should also be included. For criticality experiments, we estimate these using relative first-order sensitivity coefficients $S_{k,\sigma}=\frac{\partial k/k}{\partial \sigma \sigma}$ calculated via Generalized Perturbation Theory (GPT) as implemented in SERPENT-2 using the ECCO-33 multi-group energy structure \cite{aufieroCollisionHistorybasedApproach2015}.

Covariance matrices $\Sigma_\sigma$ were generated using SANDY \cite{fioritoJEFF33CovarianceApplication2019} (wrapping NJOY2016 \cite{muirNJOYNuclearData}). The Sandwich formula \cite{broadheadSensitivityUncertaintyBasedCriticality2004} is used to propagate these uncertainties to \keff{}, it is given by
\begin{equation}\label{eq:sandwich}
    \Sigma_k=S_{k,\sigma}^T \cdot \Sigma_\sigma \cdot S_{k,\sigma},
\end{equation}
where $\Sigma_k$ is the covariance matrix describing \keff{} of the systems under consideration and $S_{k,\sigma}$, the matrix containing the sensitivity vectors of each system, is the relative first-order sensitivity coefficients describing how changes in nuclear data affect \keff{}. These nuclear data variances are then added to the experimental variance. This ensures the adjustment does not falsely correct for other nuclear data biases. As a consequence, the integral experiments (mostly criticality) become less informative, as they are heavily influenced by uncertainties due to fissile nuclides. 

\section{Description of Cases}
\subsection{Chromium-53}
Chromium is a frequently used structural element in nuclear reactors, here 11-26\% of chromium is added to stainless steel in order to increase its corrosion resistance. Due to the scattering and capture cross sections in \nuclide{50}{Cr}, \nuclide{52}{Cr} and \nuclide{53}{Cr}, it is also important for criticality safety in some nuclear systems \cite{trkovSensitivitySelectedBenchmarks}. A major isotope with relatively poor nuclear data is the 1-10 keV range of \nuclide{53}{Cr}. Existing microscopic measurements, such as those by Guber (2011) \cite{guberNeutronCrossSectionMeasurements2011} and Stieglitz (1971) \cite{stieglitz1971kev}, are not consistent with each other. Recently, Pérez-Maroto et al. (2025) performed new capture yield measurements, it is seen as a possibility to include this experiment and complement it with integral experiments to test the proposed methodology.

To start, we selected two criticality experiments, i.e., PMI-002 and HMI-001, due to their significant sensitivity in the 1-10 keV range (see Figure \ref{fig:sensint}). These experiments use stainless steel as reflector in an intermediate spectrum. They are available in the International Handbook of Evaluated Criticality Safety Benchmark Experiments (ICSBEP) \cite{internationalcriticalitysafetybenchmarkevaluationprojecticsbepInternationalHandbookEvaluated2024}.
\begin{figure}
  \centering
  \includegraphics[width=0.4\linewidth]{../figures/sensitivity_hmi001+pmi002_Cr53.png}
  \caption{Sensitivity profiles for two criticality experiments sensitive to Cr-53 (n,$\gamma$)}\label{fig:sensint}
\end{figure}

For this case study, we infer only the capture width $\Gamma_\gamma$ at 4 keV, as it is the parameter most sensitive to criticality in this range. $E_r$ and $\Gamma_n$ are not perturbed as they are more easily derived from transmission measurements. This serves as a simplified proof-of-concept and an extension to multiple input parameters is possible. The perturbation of $\Gamma_\gamma$ is shown in Figure \ref{fig:trainingsamples}. Here, the capture yield (a) represents the connection to the microscopic measurements performed by Pérez-Maroto et al., while (b) represents the cross sections which have been incorporated into ACE files, ready for use in the SERPENT-2 Monte Carlo code. For each of these curves, the SAMMY and SERPENT codes were run with the goal of trainnig a surrogate GP.
\begin{figure}
\centering
\begin{subfigure}{.5\textwidth}
  \centering
  \includegraphics[width=\linewidth]{../figures/latest/XS_fit_nTOF.png}
  \caption{Capture yield}
\end{subfigure}%
\begin{subfigure}{.5\textwidth}
  \centering
  \includegraphics[width=\linewidth]{../figures/cr53_capture_xs_samples.png}
  \caption{Cross section}
\end{subfigure}
\caption{Random samples for capture yield (A) and cross section (B).}
\label{fig:trainingsamples}
\end{figure}

\section{Results and Discussions}
\subsection{Chromium-53}
The validation of the Gaussian Process is shown in Figure \ref{fig:GPslice}, in (a) the data points and the GP for the Pérez-Maroto data set is shown, while in (b) it is shown for PMI-002. The GP corresponds well with the predicted responses obtained from SAMMY and SERPENT, obviously since they were trained on them. Nevertheless, the tests performed on the 20\% of data points which were not included in the assimilation were also in good agreement with the GP prediction. 
\begin{figure}
\centering
\begin{subfigure}{.5\textwidth}
  \centering
  \includegraphics[width=\linewidth]{../figures/latest/validation/cr53_thin_slices.png}
  \caption{Microscopic}
  \label{fig:GPmicro}
\end{subfigure}%
\begin{subfigure}{.5\textwidth}
  \centering
  \includegraphics[width=\linewidth]{../figures/latest/validation/pmi002_slices.png}
  \caption{Integral}
  \label{fig:GPinter}
\end{subfigure}
\caption{GPs for microscopic (a) and integral (b) experiment.}
\label{fig:GPslice}
\end{figure}

We analyze several scenarios: integral experiments only, microscopic experiments only, and combinations using the independent vs. fully correlated assumptions. The results are summarized in Table \ref{tab:cr53mcmc}.
\begin{table}
\caption{Overview of posterior mean and uncertainty for different combinations of experiments included.}\label{tab:cr53mcmc}
\centering
\begin{tabular}{cccclll}
\textbf{Case}    & \textbf{PMI002}    & \textbf{HMI001}        & \textbf{ntof}   & \textbf{$\Gamma_\gamma$, eV}  & \textbf{$\sigma_\Gamma$ (\%)} & \textbf{Comment} \\ \hline
\textbf{1}       &            &               &               & 4.14  & 20         & Prior                      \\
\textbf{2}       & \checkmark & \checkmark    &               & 4.16  & 19.7         &                            \\
\textbf{3}       &            &               & \checkmark    & 3.14  & 6         &                            \\ 
\textbf{4}       & \checkmark & \checkmark    & \checkmark    & 3.15  & 6         & Fully correlated           \\
\textbf{5}       & \checkmark & \checkmark    & \checkmark    & 3.09  & 2         & Independent                \\
\textbf{6}       & \checkmark & \checkmark    &               & 5.52  & 13         & No other ND uncertainty    \\
\textbf{7}       &            &               & \checkmark    & 3.09  & 2         & Independent                \\
 \hline
\end{tabular}
\end{table}

To confine the effect of including some experiments, various scenarios are simulated. In case 1, to experiments are included, which corresponds to the prior input parameters taken from JEFF-4.0, but with an increased relative uncertainty to make the prior less informative. Then, as a baseline Eq. \ref{eq:correlated} is used unless otherwise noted. In case two, both integral experiments are included and the mean shifts only slightly and the posterior uncertainty is also not improved much. This can be attributed to the large uncertainty due to other nuclear data uncertainties in comparison to the rather limited sensitivity to the first $\Gamma_\gamma$ of \nuclide{53}{Cr}. In contrast, when these other nuclear data uncertainties are neglected, as can be seen in case 6, the bias shifts by about 30\%, while the uncertainty is reduced by 7\%.

\begin{figure}
\centering
\begin{subfigure}{.3\textwidth}
  \centering
  \includegraphics[width=\linewidth]{../figures/cr53_20r_all_1000pcm/cr53_thin_output_scatterpdf_plot.pdf}
  \caption{nTOF}
  \label{fig:MCMCntof}
\end{subfigure}%
\begin{subfigure}{.3\textwidth}
  \centering
  \includegraphics[width=\linewidth]{../figures/cr53_20r_all_1000pcm/hmi001_output_scatterpdf_plot.pdf}
  \caption{Integral - HMI001}
  \label{fig:MCMChmi1}
\end{subfigure}
\begin{subfigure}{.3\textwidth}
  \centering
  \includegraphics[width=\linewidth]{../figures/cr53_20r_all_1000pcm/pmi002_output_scatterpdf_plot.pdf}
  \caption{Integral - PMI002}
  \label{fig:MCMCpmi2}
\end{subfigure}
\caption{Scatter plots for microscopic (A) and integral (B and C) experiments showing the prior and posterior responses as a function of the input variable for Case 4.}
\label{fig:mcmcall}
\end{figure}

Now, the influence of fully correlated and independent microscopic measurement points is compared. In case 3, only the microscopic experiment from Pérez-Maroto is included with the assumption of fully correlated measurement points. Then, the posterior is optimized to be consistent with only this measurement and the $\Gamma_\gamma$ moves down. This is in contradiction with the adjustment proposed by case 6, but cannot be rejected by the posterior in case 2 where the other nuclear data uncertainties are included. The posterior uncertainty is then reduced to 6\%. Now, when the assumption of fully independent microscopic data points is used, such as in case 7 or also in Figure \ref{fig:mcmcallind}. Here the posterior seems to be confident in the prediction of $\Gamma_\gamma$ with a posterior uncertainty of 2\%.

In Figure \ref{fig:mcmcall}, corresponding to case 4 is depicted. Here the two integral experiments PMI-002 and HMI-001 as well as the microscopic dataset (regarded as fully correlated) from Pérez-Maroto are included. The posterior prediction of \keff{} moves away from the calculated integral response for PMI-002, but remains well within the uncertainty bounds imposed by experimental and other nuclear data sources. It appears that the included integral experiments contribute negligibly to the uncertainty reduction  in the $\Gamma_\gamma$ parameter at 4 keV. In order to be able to include integral experiments into this mix, several things are needed. First, the nuclear data uncertainties of other sources should be kept to a minimum, either by experimental design, or by reducing them using data assimilation with integral experiments that are sensitive to the most important other nuclear data uncertainties. Nevertheless, it seems criticality experiments are not sufficiently sensitive to the $\Gamma_\gamma$-width of \nuclide{53}{Cr} at 4 keV. A possible route to increase the sensitivity is to design experiments specifically sensitive to this energy range, e.g. pile-oscilation experiments with a significant portion of the spectrum in this energy range. On the other hand, nuclides which are more important for \keff{}, such as \nuclide{238}{U} / \nuclide{235}{U} or \nuclide{239}{Pu} might be more suitable candidates for testing as a much larger suite of highly sensitive integral experiments are available. 

\begin{figure}
\centering
\begin{subfigure}{.3\textwidth}
  \centering
  \includegraphics[width=\linewidth]{../figures/cr_53_20r_all_ind_1000pcm/cr53_thin_output_scatterpdf_plot.png}
  \caption{nTOF}
  \label{fig:MCMCntofind}
\end{subfigure}%
\begin{subfigure}{.3\textwidth}
  \centering
  \includegraphics[width=\linewidth]{../figures/cr_53_20r_all_ind_1000pcm/hmi001_output_scatterpdf_plot.png}
  \caption{Integral - HMI001}
  \label{fig:MCMChmi1ind}
\end{subfigure}
\begin{subfigure}{.3\textwidth}
  \centering
  \includegraphics[width=\linewidth]{../figures/cr_53_20r_all_ind_1000pcm/pmi002_output_scatterpdf_plot.png}
  \caption{Integral - PMI002}
  \label{fig:MCMCpmi2ind}
\end{subfigure}
\caption{Scatter plots for Case 5 (Independent assumption).}
\label{fig:mcmcallind}
\end{figure}

Finally, we simulate a hypothetical scenario with highly sensitive integral experiments (experimental uncertainty reduced to 10 pcm and other nuclear data uncertainties neglected). As seen in Figure \ref{fig:mcmcallsens}, under these ideal and unrealistic conditions, integral experiments provide significant guidance to the posterior. Although we know the integral experiments are subjected to larger uncertainties of other nuclides, it shows that when experiments with a lower uncertainty in comparison to the sensitivity are used, they can be combined with microscopic experiments under the conservative assumption that microscopic data points behave as one.

\begin{figure}
\centering
\begin{subfigure}{.3\textwidth}
  \centering
  \includegraphics[width=\linewidth]{../figures/cr53_20r_10pcm_all/cr53_thin_output_scatterpdf_plot.png}
  \caption{nTOF}
\end{subfigure}%
\begin{subfigure}{.3\textwidth}
  \centering
  \includegraphics[width=\linewidth]{../figures/cr53_20r_10pcm_all/hmi001_output_scatterpdf_plot.png}
  \caption{Integral - HMI001}
\end{subfigure}
\begin{subfigure}{.3\textwidth}
  \centering
  \includegraphics[width=\linewidth]{../figures/cr53_20r_10pcm_all/pmi002_output_scatterpdf_plot.png}
  \caption{Integral - PMI002}
\end{subfigure}
\caption{Scatter plots for the hypothetical high-sensitivity scenario.}
\label{fig:mcmcallsens}
\end{figure}

\section{Conclusions and Future Work}
In this work, a Bayesian Optimization framework was implemented to infer nuclear data parameters by consolidating microscopic and integral experiments. The methodology coupled SAMMY and SERPENT with Gaussian Process surrogates and an MCMC sampler, allowing for more efficient exploration of the posterior distribution.

The case study on \nuclide{53}{Cr} highlighted the critical challenge of weighting different data sources. We demonstrated that the assumption regarding correlations in microscopic data fundamentally alters the posterior. Treating microscopic points as independent results in an overconfident reduction of uncertainty in which integral experiments become negligible. On the other side, when microscopic data is treated as fully correlated (per experiment) and uncertainties for other nuclides are also included, the criticality experiments currently available for \nuclide{53}{Cr} provide negligible information gain. They are dominated by the uncertainties due to fissile nuclides.

The results indicate that for integral experiments to be valuable in this framework, either the experiments must be chosen such that the parameter to infer is sufficiently sensitive in comparison to other nuclear data, or the uncertainties of other nuclear data must be significantly reduced using a-priori data assimilation techniques.  

Future work should be devoted to including a realistic experimental covariance matrix to assess the validity of the assumptions regarding independent / fully correlated data samples. Second, since the case study on \nuclide{53}{Cr} did not yield significant results, the framework could be applied to a realistic scenario involving for example \nuclide{238}{U}, where many highly sensitive integral experiments are available. Some points that still should be addressed include implementing correlations between experiments and including the GP prediction uncertainty in the loglikelihood of the microscopic experiment. Although the latter is not expected to influence the results since SAMMY is deterministic, therefore the prediction uncertainty attributed to the GP response is negligible.

\section{Acknowledgments}
The authors gratefully acknowledge the financial support of the Fonds de la Recherche Scientifique (F.R.S.-FNRS) and the ENEN2plus project. The ENEN2plus project has received funding from the Euratom research and training programme 2021-2025 under grant agreement No 101061677.

\bibliographystyle{elsarticle-num} 
\bibliography{references}

% \begin{thebibliography}{00}

%% For authoryear reference style
%% \bibitem[Author(year)]{label}
%% Text of bibliographic item

% \bibitem[Lamport(1994)]{lamport94}
%   Leslie Lamport,
%   \textit{\LaTeX: a document preparation system},
%   Addison Wesley, Massachusetts,
%   2nd edition,
%   1994.

% \end{thebibliography}
% \end{document}

% \bibliographystyle{ieeetr}
% \bibliography{references}
\end{document}

\endinput
%%
%% End of file `elsarticle-template-num-names.tex'.
