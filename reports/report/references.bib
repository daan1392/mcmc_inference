
@misc{perez-maroto_50cr_2025,
	title = {{50Cr} and {53Cr} neutron capture cross sections measurement at the n\_TOF facility at {CERN}},
	copyright = {Creative Commons Attribution 4.0 International},
	url = {https://arxiv.org/abs/2506.17161},
	doi = {10.48550/ARXIV.2506.17161},
	urldate = {2025-07-02},
	publisher = {arXiv},
	author = {Pérez-Maroto, P. and Guerrero, C. and Casanovas, A. and Fernández, B. and Mendoza, E. and Alcayne, V. and Lerendegui-Marco, J. and Domingo-Pardo, C. and Quesada, J. M. and Capote, R. and Collaboration, the n\_TOF},
	year = {2025},
	note = {Version Number: 1},
	keywords = {FOS: Physical sciences, Nuclear Experiment (nucl-ex)},
	file = {Pérez-Maroto et al. - 2025 - \$^ 50 \$Cr and \$^ 53 \$Cr neutron capture cross sect.pdf:C\:\\Users\\dhouben\\Zotero\\storage\\EK9GSBF5\\Pérez-Maroto et al. - 2025 - \$^ 50 \$Cr and \$^ 53 \$Cr neutron capture cross sect.pdf:application/pdf},
}

@article{leppanenSerpentMonteCarlo2015,
  title = {The {{Serpent Monte Carlo}} Code: {{Status}}, Development and Applications in 2013},
  shorttitle = {The {{Serpent Monte Carlo}} Code},
  author = {Lepp{\"a}nen, Jaakko and Pusa, Maria and Viitanen, Tuomas and Valtavirta, Ville and Kaltiaisenaho, Toni},
  year = 2015,
  month = aug,
  journal = {Annals of Nuclear Energy},
  series = {Joint {{International Conference}} on {{Supercomputing}} in {{Nuclear Applications}} and {{Monte Carlo}} 2013, {{SNA}} + {{MC}} 2013. {{Pluri-}} and {{Trans-disciplinarity}}, {{Towards New Modeling}} and {{Numerical Simulation Paradigms}}},
  volume = {82},
  pages = {142--150},
  issn = {0306-4549},
  doi = {10.1016/j.anucene.2014.08.024},
  urldate = {2024-11-21},
  abstract = {The Serpent Monte Carlo reactor physics burnup calculation code has been developed at VTT Technical Research Centre of Finland since 2004, and is currently used in over 100 universities and research organizations around the world. This paper presents the brief history of the project, together with the currently available methods and capabilities and plans for future work. Typical user applications are introduced in the form of a summary review on Serpent-related publications over the past few years.},
  keywords = {Burnup calculation,Homogenization,Monte Carlo,Reactor physics,Serpent},
  file = {C:\Users\dhouben\Zotero\storage\E7M9NC6C\S0306454914004095.html}
}

@report{larsonUpdatedUsersGuide2008,
  title = {Updated {{User}}'s {{Guide}} for {{Sammy}}: {{Multilevel R-Matrix Fits}} to {{Neutron Data Using Bayes}}' {{Equations}}},
  shorttitle = {Updated {{User}}'s {{Guide}} for {{Sammy}}},
  author = {Larson, Nancy M},
  date = {2008-10-01},
  number = {ORNL/TM-9179/R8, 941054},
  pages = {ORNL/TM-9179/R8, 941054},
  doi = {10.2172/941054},
  url = {http://www.osti.gov/servlets/purl/941054-BqQIHy/},
  urldate = {2025-05-27},
  langid = {english},
  file = {C:\Users\dhouben\Zotero\storage\BQUUXGUA\Larson - 2008 - Updated User's Guide for Sammy Multilevel R-Matri.pdf}
}

@article{emcee,
   title={emcee: The MCMC Hammer},
   volume={125},
   ISSN={1538-3873},
   url={http://dx.doi.org/10.1086/670067},
   DOI={10.1086/670067},
   number={925},
   journal={Publications of the Astronomical Society of the Pacific},
   publisher={IOP Publishing},
   author={Foreman-Mackey, Daniel and Hogg, David W. and Lang, Dustin and Goodman, Jonathan},
   year={2013},
   month=mar, pages={306–312}
}

@article{trkovSensitivitySelectedBenchmarks,
  title = {Sensitivity of Selected Benchmarks to {{Cr-53}} and {{Cr-50}} Capture},
  author = {Trkov, Andrej and Cabellos, Oscar and Capote, Roberto},
  langid = {english},
  file = {C:\Users\dhouben\Zotero\storage\GPWHIFNI\Trkov et al. - Sensitivity of selected benchmarks to Cr-53 and Cr.pdf}
}

@article{nobreNewlyEvaluatedNeutron2021,
  title = {Newly {{Evaluated Neutron Reaction Data}} on {{Chromium Isotopes}}},
  author = {Nobre, G.P.A. and Pigni, M.T. and Brown, D.A. and Capote, R. and Trkov, A. and Guber, K.H. and Arcilla, R. and Gutierrez, J. and Cuadra, A. and Arbanas, G. and Kos, B. and Bernard, D. and Leconte, P.},
  year = 2021,
  month = mar,
  journal = {Nuclear Data Sheets},
  volume = {173},
  pages = {1--41},
  issn = {00903752},
  doi = {10.1016/j.nds.2021.04.002},
  urldate = {2025-10-02},
  langid = {english},
  file = {C:\Users\dhouben\Zotero\storage\9S3IW73L\Nobre et al. - 2021 - Newly Evaluated Neutron Reaction Data on Chromium .pdf}
}

@article{broadheadSensitivityUncertaintyBasedCriticality2004,
  title = {Sensitivity- and {{Uncertainty-Based Criticality Safety Validation Techniques}}},
  author = {Broadhead, B. L. and Rearden, B. T. and Hopper, C. M. and Wagschal, J. J. and Parks, C. V.},
  year = 2004,
  month = mar,
  journal = {Nuclear Science and Engineering},
  volume = {146},
  number = {3},
  pages = {340--366},
  issn = {0029-5639, 1943-748X},
  doi = {10.13182/NSE03-2},
  urldate = {2025-06-19},
  langid = {english},
  keywords = {broadhead},
  file = {C:\Users\dhouben\Zotero\storage\MRQMJF8V\Broadhead et al. - 2004 - Sensitivity- and Uncertainty-Based Criticality Saf.pdf}
}
@article{muirNJOYNuclearData,
  title = {The {{NJOY Nuclear Data Processing System}}, {{Version}} 2016},
  author = {Muir, D W and Boicourt, R M and Kahler, A C and Conlin, J L and Haeck, W},
  abstract = {The NJOY Nuclear Data Processing System, version 2016, is a comprehensive computer code package for producing pointwise and multigroup cross sections and related quantities from evaluated nuclear data in the ENDF-4 through ENDF-6 legacy cardimage formats. NJOY works with evaluated files for incident neutrons, photons, and charged particles, producing libraries for a wide variety of particle transport and reactor analysis codes.},
  langid = {english},
  file = {C:\Users\dhouben\Zotero\storage\6SZL2CDZ\Muir et al. - The NJOY Nuclear Data Processing System, Version 2.pdf}
}

@article{fioritoJEFF33CovarianceApplication2019,
  title = {{{JEFF-3}}.3 Covariance Application to {{ICSBEP}} Using {{SANDY}} and {{NDAST}}},
  author = {Fiorito, Luca and Dyrda, James and Fleming, Michael},
  year = 2019,
  journal = {EPJ Web of Conferences},
  volume = {211},
  pages = {07003},
  publisher = {EDP Sciences},
  issn = {2100-014X},
  doi = {10.1051/epjconf/201921107003},
  urldate = {2025-01-14},
  abstract = {Providing reliable estimates of the nuclear data contribution to the uncertainty of well-known integral benchmarks is fundamental to the validation and verification process for a nuclear data library. The Nuclear Energy Agency has produced and maintains the NDaST sensitivity tool, which integrates the DICE sensitivities and nuclear data covariances. This system has been used to rigorously and efficiently provide direct feedback to evaluators and streamline validation. For its future evolution and to identify high-priority development areas, NDaST is continuously compared against state-of-the-art codes that use different uncertainty propagation methodologies.In this work, NDaST was compared to the nuclear data sampling code SANDY for several ICSBEP criticality benchmarks using the JEFF-3.3 evaluated data. Despite excellent overall agreement for cross sections and fission neutron multiplcities, discrepancies due to processed covariance descriptions for angular distributions and prompt fission neutron spectra have identified areas where coordinated development of nuclear data covariance descriptions should be prioritised.},
  copyright = {\copyright{} The Authors, published by EDP Sciences, 2019},
  langid = {english},
  file = {C:\Users\dhouben\Zotero\storage\GZMCXD57\Fiorito et al. - 2019 - JEFF-3.3 covariance application to ICSBEP using SA.pdf}
}
@article{aufieroCollisionHistorybasedApproach2015,
  title = {A Collision History-Based Approach to Sensitivity/Perturbation Calculations in the Continuous Energy {{Monte Carlo}} Code {{SERPENT}}},
  author = {Aufiero, Manuele and Bidaud, Adrien and Hursin, Mathieu and Lepp{\"a}nen, Jaakko and Palmiotti, Giuseppe and Pelloni, Sandro and Rubiolo, Pablo},
  year = 2015,
  month = nov,
  journal = {Annals of Nuclear Energy},
  volume = {85},
  pages = {245--258},
  issn = {03064549},
  doi = {10.1016/j.anucene.2015.05.008},
  urldate = {2025-03-27},
  abstract = {In this work, the implementation of a collision history-based approach to sensitivity/perturbation calculations in the Monte Carlo code SERPENT is discussed. The proposed methods allow the calculation of the effects of nuclear data perturbation on several response functions: the effective multiplication factor, reaction rate ratios and bilinear ratios (e.g., effective kinetics parameters). SERPENT results are compared to ERANOS and TSUNAMI Generalized Perturbation Theory calculations for two fast metallic systems and for a PWR pin-cell benchmark. New methods for the calculation of sensitivities to angular scattering distributions are also presented, which adopts fully continuous (in energy and angle) Monte Carlo estimators.},
  langid = {english},
  file = {C:\Users\dhouben\Zotero\storage\S4I5HU7N\Aufiero et al. - 2015 - A collision history-based approach to sensitivity.pdf}
}

@article{hoeferMOCABAGeneralMonte2015,
  title = {{{MOCABA}}: {{A}} General {{Monte Carlo}}--{{Bayes}} Procedure for Improved Predictions of Integral Functions of Nuclear Data},
  shorttitle = {{{MOCABA}}},
  author = {Hoefer, A. and Buss, O. and Hennebach, M. and Schmid, M. and Porsch, D.},
  year = 2015,
  month = mar,
  journal = {Annals of Nuclear Energy},
  volume = {77},
  pages = {514--521},
  issn = {03064549},
  doi = {10.1016/j.anucene.2014.11.038},
  urldate = {2024-11-05},
  abstract = {MOCABA is a combination of Monte Carlo sampling and Bayesian updating algorithms for the prediction of integral functions of nuclear data, such as reactor power distributions or neutron multiplication factors. Similarly to the established Generalized Linear Least Squares (GLLS) methodology, MOCABA offers the capability to utilize integral experimental data to reduce the prior uncertainty of integral observables. The MOCABA approach, however, does not involve any series expansions and, therefore, does not suffer from the breakdown of first-order perturbation theory for large nuclear data uncertainties. This is related to the fact that, in contrast to the GLLS method, the updating mechanism within MOCABA is applied directly to the integral observables without having to ``adjust'' any nuclear data. A central part of MOCABA is the nuclear data Monte Carlo program NUDUNA, which performs random sampling of nuclear data evaluations according to their covariance information and converts them into libraries for transport code systems like MCNP or SCALE. What is special about MOCABA is that it can be applied to any integral function of nuclear data, and any integral measurement can be taken into account to improve the prediction of an integral observable of interest. In this paper we present two example applications of the MOCABA framework: the prediction of the neutron multiplication factor of a water-moderated PWR fuel assembly based on 21 criticality safety benchmark experiments and the prediction of the power distribution within a toy model reactor containing 100 fuel assemblies.},
  langid = {english},
  keywords = {MOBABA,Non-linear},
  file = {C:\Users\dhouben\Zotero\storage\QLN2Z8QL\Hoefer et al. - 2015 - MOCABA A general Monte Carlo–Bayes procedure for .pdf}
}

@article{rochmanMonteCarloNuclear2018a,
  title = {Monte {{Carlo}} Nuclear Data Adjustment via Integral Information},
  author = {Rochman, D. and Bauge, E. and Vasiliev, A. and Ferroukhi, H. and Pelloni, S. and Koning, A. J. and Sublet, J. {\relax Ch}.},
  year = 2018,
  month = dec,
  journal = {The European Physical Journal Plus},
  volume = {133},
  number = {12},
  pages = {537},
  issn = {2190-5444},
  doi = {10.1140/epjp/i2018-12361-x},
  urldate = {2024-10-31},
  abstract = {In this paper, we present three Monte Carlo methods to include integral benchmark information into the nuclear data evaluation procedure: BMC, BFMC and Mocaba. They allow to provide posterior nuclear data and their covariance information in a Bayesian sense. Different examples will be presented, among which the case of 14 integral quantities with fast neutron spectra (keff and spectral indices). Updated nuclear data for 235U, 238U and 239Pu are considered and the posterior nuclear data are tested with MCNP simulations. One of the noticeable outcomes is the reduction of uncertainties for integral quantities, obtained from the reduction of the nuclear data uncertainties and from the rise of correlations between cross sections of different isotopes. Finally, the posterior nuclear data are tested on an independent set of benchmarks, showing the limit of the adjustment methods and the necessity for selecting well representative systems.},
  langid = {english},
  file = {C:\Users\dhouben\Zotero\storage\QUJP2ZFK\Rochman et al. - 2018 - Monte Carlo nuclear data adjustment via integral i.pdf}
}

@article{hoeferLimitationsGeneralizedLinear,
  title = {Limitations of the {{Generalized Linear Least Squares Methodology}} for {{Bias Estimation}} in {{Criticality Safety Analysis}}},
  author = {Hoefer, A and Buss, O and Neuber, J C},
  abstract = {The Generalized Linear Least Squares Methodology (GLLSM) for estimating the computational bias ∆k of a nuclear fuel system's neutron multiplication factor k is based on the assumptions that nuclear data uncertainties are small and that the error of the calculated k value is exclusively coming from errors in the nuclear data evaluation used for the k calculation. Other error sources such as algorithmic deficiencies of the used neutron transport code and errors due to nuclear data processing are, however, not included within the GLLSM framework. Since for real application cases these idealized assumptions are sometimes significantly violated, we perform a toy model analysis to investigate the impact of the magnitude of nuclear data uncertainties and systematic computational errors on the coverage probability of GLLSM confidence intervals for ∆k. Furthermore, we analyze the effect of the so-called chi-square filter being a statistical method to eliminate benchmark experiments which are suspected to suffer significantly from systematic experimental errors. The toy model analysis provides some information under which conditions GLLSM predictions of the bias ∆k and its uncertainty can be trusted and under which conditions this is not the case.},
  langid = {english},
  file = {C:\Users\dhouben\Zotero\storage\C6EENP5P\Hoefer et al. - Limitations of the Generalized Linear Least Squares Methodology for Bias Estimation in Criticality S.pdf}
}

@article{guberNeutronCrossSectionMeasurements2011,
  title = {Neutron {{Cross-Section Measurements}} on {{Structural Materials}} at {{ORELA}}},
  author = {Guber, K. H. and Koehler, P. E. and Wiarda, D. E. and Harvey, J. A.},
  year = 2011,
  month = aug,
  journal = {Journal of the Korean Physical Society},
  volume = {59},
  number = {2(3)},
  pages = {1685--1688},
  issn = {0374-4884},
  doi = {10.3938/jkps.59.1685},
  urldate = {2025-11-06},
  langid = {english},
  file = {C:\Users\dhouben\Zotero\storage\AX4DF7TL\Guber et al. - 2011 - Neutron Cross-Section Measurements on Structural M.pdf}
}

@article{stieglitz1971kev,
  title={keV neutron capture and transmission measurements on 50Cr, 52Cr, 53Cr, 54Cr, 60Ni and V},
  author={Stieglitz, RG and Hockenbury, RW and Block, RC},
  journal={Nuclear Physics A},
  volume={163},
  number={2},
  pages={592--624},
  year={1971},
  publisher={Elsevier}
}

@book{internationalcriticalitysafetybenchmarkevaluationprojecticsbepInternationalHandbookEvaluated2024,
  title = {International {{Handbook}} of {{Evaluated Criticality Safety Benchmark Experiments}}},
  author = {{International Criticality Safety Benchmark Evaluation Project (ICSBEP)}},
  year = 2024,
  month = nov,
  publisher = {OECD Nuclear Energy Agency (NEA)},
  annotation = {Backup Publisher: OECD Nuclear Energy Agency (NEA)}
}
